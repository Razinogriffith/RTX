{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data retrieved from file rtxgaussian-600-300-baseline-5iter-5000.pickle\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "from rtxlib.rtx_run import setup_database, db\n",
    "from analysis_lib.one_sample_tests import KolmogorovSmirnov\n",
    "from factorial_anova_analysis import get_raw_data\n",
    "\n",
    "index = \"rtxgaussian-600-300-baseline-5iter\" \n",
    "\n",
    "results = get_raw_data(index, False, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:green'>**Found 1 different configurations in 25000 data **</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 of these:\n",
      "{   u'average_edge_duration_factor': 1.2081011415096372,\n",
      "    u'exploration_percentage': 0.19508109229406423,\n",
      "    u'freshness_cut_off_value': 359,\n",
      "    u'freshness_update_factor': 15,\n",
      "    u'max_speed_and_length_factor': 2.36432856969756,\n",
      "    u're_route_every_ticks': 63,\n",
      "    u'route_random_sigma': 0.11615606716272785}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "knobs = {}\n",
    "data = {}\n",
    "\n",
    "gaussian_best_conf = {\n",
    "    're_route_every_ticks': 63, \n",
    "    'freshness_cut_off_value': 359, \n",
    "    'max_speed_and_length_factor': 2.3643285696975598, \n",
    "    'exploration_percentage': 0.19508109229406423, \n",
    "    'freshness_update_factor': 15, \n",
    "    'route_random_sigma': 0.11615606716272785, \n",
    "    'average_edge_duration_factor': 1.2081011415096372\n",
    "}\n",
    "\n",
    "for r in results:\n",
    "    knob_str = str(r[1])\n",
    "    if r[1] == gaussian_best_conf:\n",
    "        if not knob_str in knobs:        \n",
    "            knobs[knob_str] = []\n",
    "        if len(knobs[knob_str]) < 5000:\n",
    "            knobs[knob_str].append(r[1])\n",
    "        if not knob_str in data:        \n",
    "            data[knob_str] = []\n",
    "        if len(data[knob_str]) < 5000:\n",
    "            data[knob_str].append(r[0])\n",
    "\n",
    "printmd(\"**Found \" + str(len(knobs)) + \" different configurations in \" + str(len(results)) + \" data **\", \"green\")\n",
    "\n",
    "for k in knobs:\n",
    "    print str(len(knobs[k])) + \" of these:\"\n",
    "    pp.pprint(eval(k))\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ttests with variable sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 0 comparisons found significant diffference.\n",
      "******************\n",
      "BEST CONFIGURATION\n",
      "******************\n",
      "{   u'average_edge_duration_factor': 1.2081011415096372,\n",
      "    u'exploration_percentage': 0.19508109229406423,\n",
      "    u'freshness_cut_off_value': 359,\n",
      "    u'freshness_update_factor': 15,\n",
      "    u'max_speed_and_length_factor': 2.36432856969756,\n",
      "    u're_route_every_ticks': 63,\n",
      "    u'route_random_sigma': 0.11615606716272785}\n"
     ]
    }
   ],
   "source": [
    "from analysis_lib.two_sample_tests import Ttest\n",
    "from analysis_lib.two_sample_tests import TtestPower\n",
    "from complaints_generator import generate_complaints\n",
    "from scipy.stats import binom_test\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc(\"savefig\", dpi=150)\n",
    "import random \n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string, color=None):\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))\n",
    "    \n",
    "color = {\n",
    "    \"PURPLE\": '\\033[95m',\n",
    "    \"CYAN\": '\\033[96m',\n",
    "    \"DARKCYAN\": '\\033[36m',\n",
    "    \"BLUE\": '\\033[94m',\n",
    "    \"GREEN\": '\\033[92m',\n",
    "    \"YELLOW\": '\\033[93m',\n",
    "    \"RED\": '\\033[91m',\n",
    "    \"BOLD\": '\\033[1m',\n",
    "    \"UNDERLINE\": '\\033[4m',\n",
    "    \"END\": '\\033[0m',\n",
    "}\n",
    "    \n",
    "random.seed(123456)\n",
    "\n",
    "y_key = 'overhead'\n",
    "alpha = 0.05\n",
    "necessary_power = 0.80\n",
    "\n",
    "fake_run_id = \"123456\"\n",
    "\n",
    "knob_values = sorted(knobs.keys())\n",
    "best_knob = knob_values[0]\n",
    "other_knob_values = knob_values[1:] \n",
    "\n",
    "sample_sizes = []\n",
    "pvalues = {}\n",
    "powers = {}\n",
    "\n",
    "for i in knob_values:\n",
    "    pvalues[i] = []\n",
    "    powers[i] = []\n",
    "        \n",
    "step = 100\n",
    "\n",
    "count = 0\n",
    "for other_knob_value in other_knob_values:   \n",
    "    for sample_size in range(100, 5001, step):\n",
    "    #     print \"Sample size: \" + str(sample_size)\n",
    "        sample_sizes.append(sample_size)\n",
    "\n",
    "        analysis_data = {}\n",
    "        raw_data = data[best_knob] \n",
    "#         analysis_data[0] = raw_data[:sample_size] #  also: \n",
    "        analysis_data[0] = random.sample(raw_data, sample_size)\n",
    "  \n",
    "        raw_data = data[other_knob_value] \n",
    "#         analysis_data[1] = raw_data[:sample_size] #  also: \n",
    "        analysis_data[1] = random.sample(raw_data, sample_size)\n",
    "          \n",
    "        t = Ttest(fake_run_id, y_key, alpha).start(analysis_data, {})\n",
    "        pvalues[other_knob_value].append(t[\"pvalue\"])\n",
    "        one_sided_p_value = t[\"pvalue\"]/2\n",
    "        \n",
    "        if t[\"statistic\"] < 0:\n",
    "            t_p = TtestPower(fake_run_id, y_key, t[\"effect_size\"], alpha, 'smaller').start(analysis_data, {})            \n",
    "        else: \n",
    "            t_p = TtestPower(fake_run_id, y_key, t[\"effect_size\"], alpha, 'larger').start(analysis_data, {})            \n",
    "        powers[other_knob_value].append(t_p[\"power\"])\n",
    "        \n",
    "        if one_sided_p_value < alpha and t_p[\"power\"] >= necessary_power:\n",
    "            printmd(\"**SIGNIFICANT DIFFERENCE**\", \"green\")\n",
    "            different = \"smaller\" if t[\"statistic\"] < 0 else \"larger\"\n",
    "            print \"sample size: \" + str(sample_size) \n",
    "            print \"================\"\n",
    "            print \"Overhead in \" \n",
    "            pp.pprint(eval(best_knob))\n",
    "            print \" is \" + different + \" than in \"\n",
    "            pp.pprint(eval(other_knob_value))\n",
    "            print \"================\"\n",
    "            print \"mean difference: \" + str(t[\"mean_diff\"]) \n",
    "            print \"p value: \" + str(one_sided_p_value)                                 \n",
    "            print \"effect size: \" + str(t[\"effect_size\"]) \n",
    "            print \"power: \" + str(t_p[\"power\"])\n",
    "            print \"\\n\"\n",
    "            \n",
    "            count += 1\n",
    "            if t[\"statistic\"] >= 0:\n",
    "                best_knob = other_knob_value\n",
    "            break\n",
    "\n",
    "        if sample_size == 5000:\n",
    "            printmd(\"**NO SIGNIFICANT DIFFERENCE**\", \"red\")\n",
    "            different = \"smaller\" if t[\"statistic\"] < 0 else \"larger\"\n",
    "            print \"sample size: \" + str(sample_size) \n",
    "            print \"================\"\n",
    "            print \"Overhead in \" \n",
    "            pp.pprint(eval(best_knob))\n",
    "            print \" is \" + different + \" than in \"\n",
    "            pp.pprint(eval(other_knob_value))\n",
    "            print \"================\"\n",
    "            print \"mean difference: \" + str(t[\"mean_diff\"]) \n",
    "            print \"p value: \" + str(one_sided_p_value)                                 \n",
    "            print \"effect size: \" + str(t[\"effect_size\"]) \n",
    "            print \"power: \" + str(t_p[\"power\"])\n",
    "            print \"\\n\"\n",
    "        \n",
    "print str(count) + \" out of \" + str(len(other_knob_values)) + \" comparisons found significant diffference.\"\n",
    "print \"******************\"\n",
    "print \"BEST CONFIGURATION\"\n",
    "print \"******************\"\n",
    "pp.pprint(knobs[best_knob][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m> OEDA configuration: Using elasticsearch database.\u001b[39m\n",
      "data saved to file rtxgaussian-600-300-3-5iter-5000.pickle\n",
      "len(knobs):2\n",
      "{u'freshness_update_factor': 12}\n",
      "5000\n",
      "{u'freshness_update_factor': 20}\n",
      "5000\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "results = get_raw_data(\"rtxgaussian-600-300-3-5iter\", True, 5000)\n",
    "\n",
    "b_knobs = {}\n",
    "b_data = {}\n",
    "for r in results:\n",
    "    knob_str = str(r[1])\n",
    "    if not knob_str in b_knobs:        \n",
    "        b_knobs[knob_str] = []\n",
    "    if len(b_knobs[knob_str]) < 5000:\n",
    "        b_knobs[knob_str].append(r[1])\n",
    "    if not knob_str in b_data:        \n",
    "        b_data[knob_str] = []\n",
    "    if len(b_data[knob_str]) < 5000:\n",
    "        b_data[knob_str].append(r[0])\n",
    "\n",
    "print \"len(knobs):\" + str(len(b_knobs))\n",
    "\n",
    "for k in b_knobs:\n",
    "    print k\n",
    "    print len(b_knobs[k])\n",
    "\n",
    "print \"=========\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(knobs):3\n",
      "{u'freshness_update_factor': 12}\n",
      "5000\n",
      "{u'freshness_update_factor': 20}\n",
      "5000\n",
      "{u're_route_every_ticks': 63, u'freshness_cut_off_value': 359, u'max_speed_and_length_factor': 2.36432856969756, u'exploration_percentage': 0.19508109229406423, u'freshness_update_factor': 15, u'route_random_sigma': 0.11615606716272785, u'average_edge_duration_factor': 1.2081011415096372}\n",
      "5000\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "b_knobs[best_knob] = knobs[best_knob]\n",
    "b_data[best_knob] = data[best_knob]\n",
    "\n",
    "print \"len(knobs):\" + str(len(b_knobs))\n",
    "\n",
    "for k in b_knobs:\n",
    "    print k\n",
    "    print len(b_knobs[k])\n",
    "\n",
    "print \"=========\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>**NO SIGNIFICANT DIFFERENCE**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 5000\n",
      "================\n",
      "Overhead in \n",
      "{   u'freshness_update_factor': 12}\n",
      " is smaller than in \n",
      "{   u'freshness_update_factor': 20}\n",
      "================\n",
      "mean difference: -0.00837385664225\n",
      "p value: 0.28312265119\n",
      "effect size: -0.0114733295313\n",
      "power: 0.142033920934\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:green'>**SIGNIFICANT DIFFERENCE**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 1400\n",
      "================\n",
      "Overhead in \n",
      "{   u'freshness_update_factor': 12}\n",
      " is smaller than in \n",
      "{   u'average_edge_duration_factor': 1.2081011415096372,\n",
      "    u'exploration_percentage': 0.19508109229406423,\n",
      "    u'freshness_cut_off_value': 359,\n",
      "    u'freshness_update_factor': 15,\n",
      "    u'max_speed_and_length_factor': 2.36432856969756,\n",
      "    u're_route_every_ticks': 63,\n",
      "    u'route_random_sigma': 0.11615606716272785}\n",
      "================\n",
      "mean difference: -0.0705744445022\n",
      "p value: 0.00477844591512\n",
      "effect size: -0.0980545017249\n",
      "power: 0.828638167959\n",
      "\n",
      "\n",
      "1 out of 2 comparisons found significant difference.\n",
      "******************\n",
      "BEST CONFIGURATION\n",
      "******************\n",
      "{   u'freshness_update_factor': 12}\n"
     ]
    }
   ],
   "source": [
    "y_key = 'overhead'\n",
    "alpha = 0.05\n",
    "necessary_power = 0.80\n",
    "\n",
    "fake_run_id = \"123456\"\n",
    "\n",
    "knob_values = sorted(b_knobs.keys())\n",
    "best_knob = knob_values[0]\n",
    "other_knob_values = knob_values[1:] \n",
    "\n",
    "sample_sizes = []\n",
    "pvalues = {}\n",
    "powers = {}\n",
    "\n",
    "for i in knob_values:\n",
    "    pvalues[i] = []\n",
    "    powers[i] = []\n",
    "        \n",
    "step = 100\n",
    "\n",
    "count = 0\n",
    "for other_knob_value in other_knob_values:   \n",
    "    for sample_size in range(100, 5001, step):\n",
    "    #     print \"Sample size: \" + str(sample_size)\n",
    "        sample_sizes.append(sample_size)\n",
    "\n",
    "        analysis_data = {}\n",
    "        raw_data = b_data[best_knob] \n",
    "#         analysis_data[0] = raw_data[:sample_size] #  also: \n",
    "        analysis_data[0] = random.sample(raw_data, sample_size)\n",
    "  \n",
    "        raw_data = b_data[other_knob_value] \n",
    "#         analysis_data[1] = raw_data[:sample_size] #  also: \n",
    "        analysis_data[1] = random.sample(raw_data, sample_size)\n",
    "          \n",
    "        t = Ttest(fake_run_id, y_key, alpha).start(analysis_data, {})\n",
    "        pvalues[other_knob_value].append(t[\"pvalue\"])\n",
    "        one_sided_p_value = t[\"pvalue\"]/2\n",
    "        \n",
    "        if t[\"statistic\"] < 0:\n",
    "            t_p = TtestPower(fake_run_id, y_key, t[\"effect_size\"], alpha, 'smaller').start(analysis_data, {})            \n",
    "        else: \n",
    "            t_p = TtestPower(fake_run_id, y_key, t[\"effect_size\"], alpha, 'larger').start(analysis_data, {})            \n",
    "        powers[other_knob_value].append(t_p[\"power\"])\n",
    "        \n",
    "        if one_sided_p_value < alpha and t_p[\"power\"] >= necessary_power:\n",
    "            printmd(\"**SIGNIFICANT DIFFERENCE**\", \"green\")\n",
    "            different = \"smaller\" if t[\"statistic\"] < 0 else \"larger\"\n",
    "            print \"sample size: \" + str(sample_size) \n",
    "            print \"================\"\n",
    "            print \"Overhead in \" \n",
    "            pp.pprint(eval(best_knob))\n",
    "            print \" is \" + different + \" than in \"\n",
    "            pp.pprint(eval(other_knob_value))\n",
    "            print \"================\"\n",
    "            print \"mean difference: \" + str(t[\"mean_diff\"]) \n",
    "            print \"p value: \" + str(one_sided_p_value)                                 \n",
    "            print \"effect size: \" + str(t[\"effect_size\"]) \n",
    "            print \"power: \" + str(t_p[\"power\"])\n",
    "            print \"\\n\"\n",
    "            \n",
    "            count += 1\n",
    "            if t[\"statistic\"] >= 0:\n",
    "                best_knob = other_knob_value\n",
    "            break\n",
    "        \n",
    "        if sample_size == 5000:\n",
    "            printmd(\"**NO SIGNIFICANT DIFFERENCE**\", \"red\")\n",
    "            different = \"smaller\" if t[\"statistic\"] < 0 else \"larger\"\n",
    "            print \"sample size: \" + str(sample_size) \n",
    "            print \"================\"\n",
    "            print \"Overhead in \" \n",
    "            pp.pprint(eval(best_knob))\n",
    "            print \" is \" + different + \" than in \"\n",
    "            pp.pprint(eval(other_knob_value))\n",
    "            print \"================\"\n",
    "            print \"mean difference: \" + str(t[\"mean_diff\"]) \n",
    "            print \"p value: \" + str(one_sided_p_value)                                 \n",
    "            print \"effect size: \" + str(t[\"effect_size\"]) \n",
    "            print \"power: \" + str(t_p[\"power\"])\n",
    "            print \"\\n\"\n",
    "\n",
    "print str(count) + \" out of \" + str(len(other_knob_values)) + \" comparisons found significant difference.\"\n",
    "print \"******************\"\n",
    "print \"BEST CONFIGURATION\"\n",
    "print \"******************\"\n",
    "pp.pprint(b_knobs[best_knob][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
